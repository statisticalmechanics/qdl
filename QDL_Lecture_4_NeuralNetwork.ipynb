{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QDL_Lecture_4_NeuralNetwork.ipynb","provenance":[],"authorship_tag":"ABX9TyO9BHcekrA+dH0bU9bC8vZ6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# A Quick Guide to Deep Learning with Python\n","\n","Kai Zhang, Duke Kunshan University, 2022"],"metadata":{"id":"7uGJ8rMhO6qj"}},{"cell_type":"markdown","source":["# Lecture 4 Neural Network"],"metadata":{"id":"ATYyCDXAO8dL"}},{"cell_type":"markdown","source":["<figure>\n"," <img src=\"https://drive.google.com/uc?id=1OytZvfkVNL0q3Ai-q2b5GTNzpijaLX3R\">\n"," <figcaption align=\"left\">Figure 1. Neural network. X: input. Z: logit. A: activation. n, n1, n2, ..., K number of neurons in each layer.\n"," </figcaption>\n","</figure>\n","\n","\n","#1. Architecture of fully connected neural network\n","\n","Here, we define a three-layer dense neural network multiclass classifier used for, e.g. the MNIST digit image recognition [Lecun 1998] (Figure 1). \n","\n","number of neurons: $n\\rightarrow n_1 \\rightarrow n_2 \\rightarrow K$.\n","\n","$m$: number of instances (samples), can be either the whole data set or a mini batch.\n","\n","$n$: number of features (inputs).\n","\n","$K$: number of classes (outputs).\n","\n","$n_i$, number of neurons in the $i$th layer. $n_0=n$. $n_3=K$. For MNIST, $n=28^2=784$ and $K=10$.\n","\n","$A(n, m)$: an $n$-row by $m$-column matrix.\n","\n","We adopt the convention in Andrew Ng's lecture that the input matrix $X(n, m)$ is shaped with each sample $\\vec{x}_i$ being a column vector.\n","\n","The activation function $h_1(z) =h_2(z) = \\sigma(z)$ and $h_3(z)=s(z)$, where the sigmoid function $\\sigma(z) = 1/(1+\\exp(-z))$ and the softmax function $$s(z_k) =  \\frac{\\exp(z_k)}{\\sum\\limits_{j=1}^K \\exp(z_j)}.$$"],"metadata":{"id":"jav_H3SIRc9x"}},{"cell_type":"markdown","source":["# 2. Forward propagation\n","\n","## 2.1 Input Layer\n","\n","**Inputs**: \n","\\begin{equation}\n","X(n,m) = \n","\\begin{pmatrix}\n","    x_{11} & x_{12} & x_{13} & \\cdots  & x_{1m} \\\\\n","    x_{21} & x_{22} & x_{23} & \\cdots  & x_{2m} \\\\\n","    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","    x_{n1} & x_{n2} & x_{n3} & \\cdots  & x_{nm}\n","\\end{pmatrix}\n","=\\left(\n","  \\begin{array}{cccc}\n","    |& | & & |\\\\\n","    \\vec{x}_{1} & \\vec{x}_{2} & \\cdots & \\vec{x}_{m} \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)\n","\\end{equation}\n","\n","**Labels**:\n","\\begin{equation}\n","\\vec{y}^{T} = [y_1~~y_2~~\\dots~~y_m],~~~y_i\\in \\{1, \\dots, K\\}\n","\\end{equation}\n","\n","One-hot representation\n","\\begin{equation}\n","P(K, m)\n","=\\left(\n","  \\begin{array}{cccc}\n","    | & | & & |\\\\\n","    \\vec{p}_{1} & \\vec{p}_{2} & \\dots & \\vec{p}_{m} \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)\n",",~p_{ki} = 1~{\\rm if}~y_{i}=k;=0~{\\rm otherwise}\n","\\end{equation}\n","\n","##2.2 1st Hidden Layer\n","\n","**Weights** of the 1st hidden layer:\n","\\begin{equation}\n","W^{[1]}(n_1, n)=\n","\\begin{pmatrix}\n","    w_{11}^{[1]} & w_{12}^{[1]}  & w_{13}^{[1]}  & \\dots  & w_{1n}^{[1]}  \\\\\n","    w_{21}^{[1]}  & w_{22}^{[1]} & w_{23}^{[1]}  & \\dots  & w_{2n}^{[1]}  \\\\\n","    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n","    w_{n_11}^{[1]}  & w_{n_12}^{[1]}  & w_{n_13}^{[1]}  & \\dots  & w_{n_1n}^{[1]} \n","\\end{pmatrix}\n","=\n","\\left(\n","  \\begin{array}{c}\n","    - \\vec{w}^{[1]T}_{1} - \\\\\n","    - \\vec{w}^{[1]T}_{2} - \\\\\n","             \\vdots              \\\\\n","    - \\vec{w}^{[1]T}_{n_1} -\n","  \\end{array}\n","\\right)\n","\\end{equation}\n","\n","**Biases** of the 1st hidden layer:\n","\\begin{equation}\n","\\vec{b}^{[1]}(n_1, 1) = \n","\\left(\n","  \\begin{array}{c}\n","  b^{[1]}_1\\\\\n","    b^{[1]}_2\\\\\n","  \\vdots \\\\\n","    b^{[1]}_{n_1}\\\\\n","  \\end{array}\n","\\right)~~~~~\n","B^{[1]}(n_1, m)= \n","\\left(\n","  \\begin{array}{cccc}\n","    | & | & & |\\\\\n","  \\vec{b}^{[1]}  &\\vec{b}^{[1]} & \\cdots & \\vec{b}^{[1]} \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)\n","\\end{equation}\n","\n","**Logit**:\n","\\begin{equation}\n","Z^{[1]}(n_1, m) =  W^{[1]}X  + B^{[1]}=\n","\\left(\n"," \\begin{array}{c c}\n","  \\vec{w}^{[1]T}_{1} \\vec{x}_{1}  + b^{[1]}_1 & \\cdots \\\\\n","  \\vec{w}^{[1]T}_{2} \\vec{x}_{1}  + b^{[1]}_2 & \\cdots \\\\\n","   \\vdots & \\vdots \\\\\n","  \\vec{w}^{[1]T}_{n_1} \\vec{x}_{1}  + b^{[1]}_{n_1} & \\cdots \n","  \\end{array}\n","\\right)=\n","\\left(\n","  \\begin{array}{cccc}\n","    | & | & & |\\\\\n","    \\vec{z}^{[1]}_1 & \\vec{z}^{[1]}_2 & \\cdots & \\vec{z}^{[1]}_m \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)\n","\\end{equation}\n","\n","**Activation**:\n","\\begin{equation}\n","A^{[1]}(n_1, m) = \\sigma(Z^{[1]})=\n","\\left(\n","  \\begin{array}{cccc}\n","    | & | & & |\\\\\n","    \\sigma(\\vec{z}^{[1]}_1) & \\sigma(\\vec{z}^{[1]}_2) & \\cdots & \\sigma(\\vec{z}^{[1]}_m) \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)=\n","\\left(\n","  \\begin{array}{cccc}\n","    | & | & & |\\\\\n","    \\vec{a}^{[1]}_1 & \\vec{a}^{[1]}_2 & \\cdots & \\vec{a}^{[1]}_m \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)\n","\\end{equation}\n","\n","##2.3 2nd Hidden Layer\n","\n","**Weights**: \n","$W^{[2]}(n_2, n_1)$\n","\n","**Biases**: \n","$\\vec{b}^{[2]}(n_2, 1) ~~~ ~~  B^{[2]}(n_2, m)$\n","\n","**Logit**:\n","$Z^{[2]}(n_2, m) =  W^{[2]}A^{[1]} + B^{[2]}$\n","\n","**Activation**:\n","$A^{[2]}(n_2, m) = \\sigma(Z^{[2]})$\n","\n","##2.4 Output Layer ($n_3=K$)\n","\n","**Weights**: \n","$W^{[3]}(K, n_2)$\n","\n","**Biases**: \n","$\\vec{b}^{[3]}(K, 1) ~~~ ~~  B^{[3]}(K, m)$\n","\n","**Logit**:\n","$Z^{[3]}(K, m) =  W^{[3]}A^{[2]} + B^{[3]}$\n","\n","**Activation via Softmax Function**:\n","\\begin{equation}\n","A^{[3]}(K, m) = s(Z^{[3]}) = \\left(\n","  \\begin{array}{cccc}\n","    | & | & & |\\\\\n","    \\vec{a}^{[3]}_1 & \\vec{a}^{[3]}_2 & \\cdots & \\vec{a}^{[3]}_m \\\\\n","    | & | & & | \n","  \\end{array}\n","\\right)\n","\\end{equation}\n","where\n","\\begin{equation}\n","a^{[3]}_{ki}=s(z^{[3]}_{ki})= \\frac{ \\exp(z^{[3]}_{ki})}{\\sum\\limits_{j=1}^{K} \\exp(z^{[3]}_{ji})}\\equiv \\hat{p}_{ki}\n","\\end{equation}\n","is the probability that sample $i$ belongs to class $k$. \n","\n","To predict the class label\n","\\begin{equation}\n","  \\begin{split}\n","\\hat{y}_i &= \\arg\\max_k  ~[a^{[3]}_{1i}~~a^{[3]}_{2i}~~\\dots~~a^{[3]}_{ki}~~\\dots~~a^{[3]}_{Ki}]\\\\\n","& =\\arg\\max_k  ~[z^{[3]}_{1i}~~z^{[3]}_{2i}~~\\dots~~z^{[3]}_{ki}~~\\dots~~z^{[3]}_{Ki}]\\\\\n","&\\in\\{1,~2,~\\dots,~K\\}~~~~~(i=1,2,\\dots,m)\n","  \\end{split}\n","\\end{equation}\n","\n","**Cost Function**\n","\n","cross entropy [shannon1948, jaynes1957, kullback1951]\n","\\begin{equation}\n","J = - \\sum_{i=1}^m \\sum_{k=1}^K p_{ki} \\log \\hat{p}_{ki}  = - {\\rm SUM} (P \\ast \\log \\hat{P})\n","\\end{equation}\n","where $\\ast$ is element-wise multiplication and ${\\rm SUM}$ is to sum all elements of the matrix.\n","\n","\n","<figure>\n"," <img src=\"https://drive.google.com/uc?id=1HLszhHKVhrvXQqz__WdSSyHetSk01_OE\" width = \"600\">\n"," <figcaption align=\"left\">Figure 2. Forward and backward propagation in neural network.\n"," </figcaption>\n","</figure>\n"],"metadata":{"id":"fvTpeZGJWjWF"}},{"cell_type":"markdown","source":["# 3. Backward propagation\n","\n","The forward propagation can be formally written as, if the biases terms are neglected or absorbed,\n","\\begin{equation}\n","\\hat{P}=s(W^{[3]}\\sigma(W^{[2]}\\sigma(W^{[1]}X)))\n","\\end{equation}\n","and in the following notation $dX$ means $\\partial J/\\partial X$.\n","\n","$\\frac{\\partial J}{\\partial Z^{[3]}} = dZ^{[3]} = \\hat{P} - P = A^{[3]} - P$\n","\n","$dW^{[3]} = dZ^{[3]}  A^{[2]T}  $\n","\n","$d\\vec{b}^{[3]} = dZ^{[3]}  \\vec{1}$\n","\n","$dA^{[2]} = W^{[3]T} dZ^{[3]} $\n","\n","$dZ^{[2]} = dA^{[2]} \\ast A^{[2]} \\ast (E - A^{[2]} )  $\n","\n","$dW^{[2]} = dZ^{[2]}  A^{[1]T}  $\n","\n","$d\\vec{b}^{[2]} = dZ^{[2]}  \\vec{1}$\n","\n","$dA^{[1]} = W^{[2]T} dZ^{[2]} $\n","\n","$dZ^{[1]} = dA^{[1]} \\ast A^{[1]} \\ast (E - A^{[1]} ) $\n","\n","$dW^{[1]} = dZ^{[1]}  X^{T}  $\n","\n","$d\\vec{b}^{[1]} = dZ^{[1]}  \\vec{1}$\n","\n","where matrix $E=\\begin{pmatrix}\n","    1 & 1   & \\dots  & 1 \\\\\n","    \\vdots & \\vdots  & \\vdots & \\vdots \\\\\n","    1 & 1  &  \\dots  &1\n","\\end{pmatrix}$  has the same dimension as $A^{[l]}$ and vector $\\vec{1}^{T}=[1, 1, \\dots, 1]$ is of length $m$.  The definition of  variable $dA^{[l]}$  can be omitted by applying $W^{[l]T} dZ^{[l]}$,  but we keep it for clarity."],"metadata":{"id":"nqV8TCU9akR3"}},{"cell_type":"markdown","source":["# 4. Python implementation with OOP\n","\n","Here we modify the code from [raschka2015] to implement mini-batch gradient descent optimization with forward and backward propagation."],"metadata":{"id":"76Eu1nL9bVeV"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"xRTf-LvlO7P1","executionInfo":{"status":"ok","timestamp":1652922589653,"user_tz":240,"elapsed":184,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"QPfs9AIvcFlP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652922611922,"user_tz":240,"elapsed":3333,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"60325987-dc73-44c4-cea2-d638df979fd9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["#from sklearn.preprocessing import MinMaxScaler\n","#scaler = MinMaxScaler()\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(train_images.reshape(60000, 28*28).astype(np.float64))\n","y_train = train_labels\n","\n","X_test = scaler.transform(test_images.reshape(10000, 28*28).astype(np.float64)) # do not fit\n","y_test = test_labels"],"metadata":{"id":"i1o3sg5Wkq1F","executionInfo":{"status":"ok","timestamp":1652922697171,"user_tz":240,"elapsed":944,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X_train = np.copy(X_train).T\n","X_test = np.copy(X_test).T\n","print(X_train.shape,X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXOvqJknmh5o","executionInfo":{"status":"ok","timestamp":1652922771980,"user_tz":240,"elapsed":145,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"4996addf-0689-4d2f-c8c6-ef08c13bebc8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(784, 60000) (784, 10000)\n"]}]},{"cell_type":"code","source":["a = [1,2,3]\n","\n","for i,j in enumerate(a):\n","  print(i,j)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SM5i1ATO5TKH","executionInfo":{"status":"ok","timestamp":1652923169533,"user_tz":240,"elapsed":9,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"8ad47a7a-e03b-4a0e-81ff-7ffbad83a94d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["0 1\n","1 2\n","2 3\n"]}]},{"cell_type":"code","source":["class MLP2(object):\n","    \"\"\" MLP classifier with 2 hidden layers\n","        number of neurons in each layer:\n","        n_features (n) -> n1 -> n2 -> n_output (K)\n","        m_instances (m): number of instances in input matrix X\n","        X should be reshaped to [n_features, m_instances] or [n, m]\n","        X should also be normalized before feeded to the 1st layer\n","    \"\"\"\n","    def __init__(self, n1=100, n2=30, n_epochs=50, eta=0.001, batch_size=1, seed=None):\n","        self.random = np.random.RandomState(seed)\n","        self.n1 = n1 # number of neurons in 1st hidden layer\n","        self.n2 = n2 # number of neurons in 2nd hidden layer\n","        self.n_epochs = n_epochs\n","        self.eta = eta # learning rate\n","        self.batch_size = batch_size\n","        \n","    def _onehot(self, y, n_classes):\n","        \"\"\"\n","        y: shape=[m] with class labels: 0, ..., K-1        \n","        p: onehot representation of y, shape=[K, m]\n","        pki: probability that ith sample is class K\n","        \"\"\"\n","        p = np.zeros([n_classes, y.shape[0]]) # [K, m]\n","        for i, k in enumerate(y.astype(int)):\n","            p[k, i] = 1. #kth class, ith sample    \n","        return p\n","\n","    def _sigmoid(self, t):\n","        \"\"\" logistic function\n","        \"\"\"\n","        return 1. / (1. + np.exp(-np.clip(t, -150, 150)))\n","    \n","    def _softmax(self, z):\n","        \"\"\" softmax function\n","        z: shape=[K, m]\n","        \"\"\"\n","        return np.exp(z) / np.sum(np.exp(z), axis=0)\n","\n","    def _forward(self, X):\n","        Z1 = np.dot(self.W1, X) + self.b1 \n","        # [n1, m] <- [n1, n] [n, m] + [n1, ]\n","        A1 = self._sigmoid(Z1)\n","        Z2 = np.dot(self.W2, A1) + self.b2 \n","        # [n2, m] <- [n2, n1] [n1, m] + [n2, ]\n","        A2 = self._sigmoid(Z2)\n","        Z3 = np.dot(self.W3, A2) + self.b3 \n","        # [K, m] <- [K, n2] [n2, m] + [K, ]\n","        A3 = self._softmax(Z3) # softmax function\n","        return Z1, A1, Z2, A2, Z3, A3\n","    \n","    def _compute_cost(self, p, p_pred):\n","        \"\"\"\n","        cross entropy\n","        p: one hot representation of y labels, shape=[K, m]\n","        p_pred: softmax function output, probability, shape=[K, m]\n","        J =  - sum_i sum_k ( pki * log pki_pred ) \n","        sum over samples i and classes k\n","        \"\"\"\n","        epsilon = 1e-5 # to avoid log 0.0\n","        cost = -np.sum(p * np.log(p_pred+epsilon)) \n","        # not normalized by m\n","        # element-wise multiply and sum K*m elements\n","        return cost\n","    \n","    def predict(self, X):\n","        Z1, A1, Z2, A2, Z3, A3 = self._forward(X)\n","        y_pred = np.argmax(Z3, axis=0) #along class K axis\n","        return y_pred\n","        \n","    def fit(self, X_train, y_train, X_valid, y_valid):\n","        \"\"\"gradient descent with backward propagation\n","        \"\"\"\n","        n_output = np.unique(y_train).shape[0] # number of classes K\n","        n_features = X_train.shape[0] # n, X shape (n,m)\n","        m_instances = X_train.shape[1] # m\n","        \n","        self.b1 = np.zeros(shape=(self.n1, 1)) # [n1, ]broadcast\n","        self.W1 = self.random.normal(loc=0.0, scale=0.1, size=(self.n1, n_features))\n","        \n","        self.b2 = np.zeros(shape=(self.n2, 1)) # [n2, ]\n","        self.W2 = self.random.normal(loc=0.0, scale=0.1, size=(self.n2, self.n1))\n","        \n","        self.b3 = np.zeros(shape=(n_output, 1)) # [K, ]\n","        self.W3 = self.random.normal(loc=0.0, scale=0.1, size=(n_output, self.n2))\n","        \n","        p_train = self._onehot(y_train, n_output) # [K, m]\n","        \n","        n_batches = m_instances // self.batch_size #floor division\n","        \n","        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n","        \n","        for epoch in range(self.n_epochs):\n","            for batch_index in range(n_batches):\n","                np.random.seed(epoch * n_batches + batch_index) # new seed\n","                indices = np.random.randint(m_instances, size=self.batch_size) \n","               # batch_size numbers out of m\n","                X_batch, y_batch, p_batch = X_train[:,indices], y_train[indices], p_train[:, indices] \n","               # shape [n, batch_size]\n","                Z1, A1, Z2, A2, Z3, A3 = self._forward(X_batch)\n","                \n","                dZ3 = A3 - p_batch # dJ/dZ3=dJ/dA3*dA3/dZ3[K, m]\n","                dW3 = np.dot(dZ3, A2.T) # dJ/dW3 = dJ/dZ3*dZ3/dW3 [K, n2]\n","                db3 = np.sum(dZ3, axis=1, keepdims=True) # [K]\n","                \n","                dA2 = np.dot(self.W3.T, dZ3) \n","                # dJ/dA2 = dJ/dZ3*dZ3/dA2 [n2, m] <- [n2, K][K, m]\n","                dZ2 = dA2 * A2 * (1. - A2) # [n2, m]\n","                dW2 = np.dot(dZ2, A1.T) # [n2, n1] <= [n2, m][m, n1]\n","                db2 = np.sum(dZ2, axis=1, keepdims=True) # [n2]\n","                \n","                dA1 = np.dot(self.W2.T, dZ2) # [n1, m] <- [n1,n2][n2,m]\n","                dZ1 = dA1 * A1 * (1. - A1) # [n1, m]\n","                dW1 = np.dot(dZ1, X_batch.T)# [n1, n] <- [n1,m][m,n] \n","                db1 = np.sum(dZ1, axis=1, keepdims=True)  # [n1] \n","                \n","                self.W1 -= self.eta * dW1 # W = W - eta*dJ/dW\n","                self.b1 -= self.eta * db1\n","                self.W2 -= self.eta * dW2\n","                self.b2 -= self.eta * db2\n","                self.W3 -= self.eta * dW3\n","                self.b3 -= self.eta * db3\n","                \n","            Z1, A1, Z2, A2, Z3, A3 = self._forward(X_train)\n","            cost = self._compute_cost(p=p_train, p_pred=A3)\n","            y_train_pred = self.predict(X_train)\n","            y_valid_pred = self.predict(X_valid)\n","            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) / X_train.shape[1])\n","            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) / X_valid.shape[1])\n","            \n","            print(\"epoch\", epoch, \"cost\", cost, \"train_acc\", train_acc, \"valid_acc\", valid_acc)\n","\n","            self.eval_['cost'].append(cost)\n","            self.eval_['train_acc'].append(train_acc)\n","            self.eval_['valid_acc'].append(valid_acc)\n","            \n","        return self"],"metadata":{"id":"w8Zk14_0bp07","executionInfo":{"status":"ok","timestamp":1652924451284,"user_tz":240,"elapsed":139,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = MLP2(n1=100, n2=30, n_epochs=150, eta=0.001, batch_size = 100, seed=42)"],"metadata":{"id":"jZyUpBEqcQJx","executionInfo":{"status":"ok","timestamp":1652924476841,"user_tz":240,"elapsed":125,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model.fit(X_train=X_train, y_train=y_train, X_valid=X_test,y_valid=y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rytlZ4mknooV","executionInfo":{"status":"ok","timestamp":1652925059640,"user_tz":240,"elapsed":543039,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"315248fc-e0d0-45c1-9a16-5d1c6881f45b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:128: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0 cost 49617.09755455986 train_acc 0.8123833333333333 valid_acc 0.8196\n","epoch 1 cost 25737.083454205014 train_acc 0.8874333333333333 valid_acc 0.8892\n","epoch 2 cost 19932.964697322834 train_acc 0.9077 valid_acc 0.9062\n","epoch 3 cost 17176.171871674378 train_acc 0.9184 valid_acc 0.9164\n","epoch 4 cost 15444.561010551613 train_acc 0.9263166666666667 valid_acc 0.9218\n","epoch 5 cost 14154.381084682314 train_acc 0.9324666666666667 valid_acc 0.9265\n","epoch 6 cost 13160.614308560751 train_acc 0.9378 valid_acc 0.9307\n","epoch 7 cost 12221.328915749757 train_acc 0.9424666666666667 valid_acc 0.9323\n","epoch 8 cost 11443.495769107385 train_acc 0.9458666666666666 valid_acc 0.9353\n","epoch 9 cost 10763.863940974024 train_acc 0.9494833333333333 valid_acc 0.9378\n","epoch 10 cost 10119.002215529905 train_acc 0.9529833333333333 valid_acc 0.9401\n","epoch 11 cost 9541.556469512678 train_acc 0.9555666666666667 valid_acc 0.9427\n","epoch 12 cost 9066.15035369186 train_acc 0.9577666666666667 valid_acc 0.9449\n","epoch 13 cost 8552.320831976072 train_acc 0.9608 valid_acc 0.946\n","epoch 14 cost 8085.907372285196 train_acc 0.9632333333333334 valid_acc 0.9482\n","epoch 15 cost 7677.463963960889 train_acc 0.9652166666666666 valid_acc 0.9496\n","epoch 16 cost 7281.7222633370675 train_acc 0.9673333333333334 valid_acc 0.9501\n","epoch 17 cost 6941.597612991604 train_acc 0.9688666666666667 valid_acc 0.9519\n","epoch 18 cost 6575.195813607982 train_acc 0.9709833333333333 valid_acc 0.9529\n","epoch 19 cost 6244.444967127924 train_acc 0.97255 valid_acc 0.9537\n","epoch 20 cost 5945.4173116860675 train_acc 0.97355 valid_acc 0.9554\n","epoch 21 cost 5655.94814418204 train_acc 0.9750666666666666 valid_acc 0.957\n","epoch 22 cost 5356.64108126852 train_acc 0.9767666666666667 valid_acc 0.9566\n","epoch 23 cost 5102.566984740182 train_acc 0.9783833333333334 valid_acc 0.9581\n","epoch 24 cost 4904.907120503896 train_acc 0.97945 valid_acc 0.9578\n","epoch 25 cost 4642.089339907952 train_acc 0.9805166666666667 valid_acc 0.9578\n","epoch 26 cost 4417.005576485189 train_acc 0.98155 valid_acc 0.9585\n","epoch 27 cost 4230.738100879036 train_acc 0.98295 valid_acc 0.9606\n","epoch 28 cost 4008.7326873590564 train_acc 0.9845166666666667 valid_acc 0.9618\n","epoch 29 cost 3820.24246334352 train_acc 0.9850333333333333 valid_acc 0.9619\n","epoch 30 cost 3673.3024412923323 train_acc 0.98585 valid_acc 0.9616\n","epoch 31 cost 3502.9327607148234 train_acc 0.98625 valid_acc 0.9616\n","epoch 32 cost 3326.989872877677 train_acc 0.9870833333333333 valid_acc 0.9621\n","epoch 33 cost 3188.788260135785 train_acc 0.9877 valid_acc 0.9625\n","epoch 34 cost 3039.608428086626 train_acc 0.9884333333333334 valid_acc 0.9631\n","epoch 35 cost 2915.033724932194 train_acc 0.9893333333333333 valid_acc 0.9639\n","epoch 36 cost 2781.1728314964585 train_acc 0.98995 valid_acc 0.9634\n","epoch 37 cost 2675.428569059257 train_acc 0.99025 valid_acc 0.9634\n","epoch 38 cost 2564.7384408782964 train_acc 0.9909333333333333 valid_acc 0.9641\n","epoch 39 cost 2431.750670764332 train_acc 0.9916333333333334 valid_acc 0.9639\n","epoch 40 cost 2340.5784360473635 train_acc 0.9924666666666667 valid_acc 0.9635\n","epoch 41 cost 2245.4911972721316 train_acc 0.99285 valid_acc 0.9643\n","epoch 42 cost 2133.0006789957138 train_acc 0.99315 valid_acc 0.9655\n","epoch 43 cost 2039.5989011882725 train_acc 0.9934833333333334 valid_acc 0.9645\n","epoch 44 cost 1950.4927903847004 train_acc 0.9941666666666666 valid_acc 0.9646\n","epoch 45 cost 1869.7282447049195 train_acc 0.9945 valid_acc 0.9648\n","epoch 46 cost 1811.3679468410492 train_acc 0.9948333333333333 valid_acc 0.964\n","epoch 47 cost 1718.7299070629929 train_acc 0.99555 valid_acc 0.965\n","epoch 48 cost 1656.8134556301106 train_acc 0.9955166666666667 valid_acc 0.9655\n","epoch 49 cost 1591.2048591446824 train_acc 0.9958 valid_acc 0.9657\n","epoch 50 cost 1540.642265234651 train_acc 0.9959 valid_acc 0.9656\n","epoch 51 cost 1475.510285368507 train_acc 0.9961666666666666 valid_acc 0.9644\n","epoch 52 cost 1410.9298532801276 train_acc 0.9967 valid_acc 0.9656\n","epoch 53 cost 1360.0321694817792 train_acc 0.9967833333333334 valid_acc 0.9658\n","epoch 54 cost 1306.798675746526 train_acc 0.9970333333333333 valid_acc 0.9655\n","epoch 55 cost 1254.5740510586907 train_acc 0.99715 valid_acc 0.965\n","epoch 56 cost 1212.4475005290071 train_acc 0.9973 valid_acc 0.9663\n","epoch 57 cost 1171.1089176960659 train_acc 0.99745 valid_acc 0.9663\n","epoch 58 cost 1121.8254608508937 train_acc 0.9978166666666667 valid_acc 0.9662\n","epoch 59 cost 1084.8603670342286 train_acc 0.9978666666666667 valid_acc 0.9662\n","epoch 60 cost 1048.0559082415868 train_acc 0.9979833333333333 valid_acc 0.9664\n","epoch 61 cost 1017.1332243155907 train_acc 0.9982 valid_acc 0.9653\n","epoch 62 cost 978.5902108869044 train_acc 0.9983666666666666 valid_acc 0.9657\n","epoch 63 cost 947.6905384163225 train_acc 0.9983833333333333 valid_acc 0.9656\n","epoch 64 cost 908.3772073581621 train_acc 0.9984833333333333 valid_acc 0.9654\n","epoch 65 cost 880.141156477171 train_acc 0.9985166666666667 valid_acc 0.9654\n","epoch 66 cost 853.148168847172 train_acc 0.9988333333333334 valid_acc 0.9658\n","epoch 67 cost 822.9568245139831 train_acc 0.99895 valid_acc 0.9663\n","epoch 68 cost 794.0647875878974 train_acc 0.99895 valid_acc 0.9662\n","epoch 69 cost 776.0741201292299 train_acc 0.9988166666666667 valid_acc 0.9662\n","epoch 70 cost 747.636796085403 train_acc 0.9989 valid_acc 0.9658\n","epoch 71 cost 723.3904115141318 train_acc 0.9991166666666667 valid_acc 0.9663\n","epoch 72 cost 699.5823268985945 train_acc 0.9992 valid_acc 0.9659\n","epoch 73 cost 681.8821897519423 train_acc 0.99925 valid_acc 0.9657\n","epoch 74 cost 662.6606926022025 train_acc 0.9991666666666666 valid_acc 0.9658\n","epoch 75 cost 644.5803612887104 train_acc 0.99925 valid_acc 0.9658\n","epoch 76 cost 626.274090541482 train_acc 0.99935 valid_acc 0.9662\n","epoch 77 cost 604.6722165486068 train_acc 0.9994333333333333 valid_acc 0.9662\n","epoch 78 cost 590.0781535205881 train_acc 0.9994666666666666 valid_acc 0.966\n","epoch 79 cost 573.2319639216881 train_acc 0.9994666666666666 valid_acc 0.9658\n","epoch 80 cost 557.5638872587563 train_acc 0.9995833333333334 valid_acc 0.9655\n","epoch 81 cost 542.2450261947332 train_acc 0.9995666666666667 valid_acc 0.9655\n","epoch 82 cost 528.471750664715 train_acc 0.9996 valid_acc 0.9659\n","epoch 83 cost 515.9665109245442 train_acc 0.9996666666666667 valid_acc 0.9665\n","epoch 84 cost 502.42863309013234 train_acc 0.9997166666666667 valid_acc 0.9657\n","epoch 85 cost 490.61115451437064 train_acc 0.99975 valid_acc 0.9663\n","epoch 86 cost 477.7751609999117 train_acc 0.9997666666666667 valid_acc 0.9659\n","epoch 87 cost 461.6681782947994 train_acc 0.9997833333333334 valid_acc 0.9658\n","epoch 88 cost 451.1028664294508 train_acc 0.9997833333333334 valid_acc 0.9664\n","epoch 89 cost 446.5059678832182 train_acc 0.99975 valid_acc 0.9661\n","epoch 90 cost 431.561239126011 train_acc 0.9997666666666667 valid_acc 0.966\n","epoch 91 cost 423.8241257970403 train_acc 0.9997833333333334 valid_acc 0.9662\n","epoch 92 cost 413.22810158001823 train_acc 0.9997833333333334 valid_acc 0.9659\n","epoch 93 cost 405.06362132021206 train_acc 0.99985 valid_acc 0.9656\n","epoch 94 cost 392.7305753516032 train_acc 0.9998333333333334 valid_acc 0.9665\n","epoch 95 cost 385.12884435680974 train_acc 0.9998166666666667 valid_acc 0.9663\n","epoch 96 cost 375.28882408469656 train_acc 0.9998166666666667 valid_acc 0.9664\n","epoch 97 cost 369.11340148477353 train_acc 0.9999166666666667 valid_acc 0.9665\n","epoch 98 cost 359.4566434852482 train_acc 0.9999166666666667 valid_acc 0.9664\n","epoch 99 cost 352.2157071806331 train_acc 0.99985 valid_acc 0.9664\n","epoch 100 cost 343.59049010386025 train_acc 0.9999 valid_acc 0.9663\n","epoch 101 cost 337.5760433633978 train_acc 0.9999333333333333 valid_acc 0.966\n","epoch 102 cost 329.4365770404392 train_acc 0.99995 valid_acc 0.9665\n","epoch 103 cost 321.95255478823367 train_acc 0.9999333333333333 valid_acc 0.9666\n","epoch 104 cost 315.74312204403776 train_acc 0.99995 valid_acc 0.9667\n","epoch 105 cost 310.9538626116044 train_acc 0.99995 valid_acc 0.9667\n","epoch 106 cost 305.401447715466 train_acc 0.99995 valid_acc 0.9665\n","epoch 107 cost 298.7144185334602 train_acc 0.9999833333333333 valid_acc 0.9661\n","epoch 108 cost 293.0435356436618 train_acc 1.0 valid_acc 0.9667\n","epoch 109 cost 288.0570518266889 train_acc 1.0 valid_acc 0.9665\n","epoch 110 cost 281.6214389272143 train_acc 1.0 valid_acc 0.9666\n","epoch 111 cost 277.445679982176 train_acc 0.9999833333333333 valid_acc 0.9661\n","epoch 112 cost 272.40664888194783 train_acc 1.0 valid_acc 0.9661\n","epoch 113 cost 266.9750479242634 train_acc 1.0 valid_acc 0.9663\n","epoch 114 cost 262.72232229531664 train_acc 1.0 valid_acc 0.9666\n","epoch 115 cost 257.5288541900312 train_acc 1.0 valid_acc 0.9663\n","epoch 116 cost 253.56592136244433 train_acc 0.9999666666666667 valid_acc 0.9662\n","epoch 117 cost 249.80825886797254 train_acc 0.9999833333333333 valid_acc 0.9665\n","epoch 118 cost 245.1452377745712 train_acc 1.0 valid_acc 0.9664\n","epoch 119 cost 241.36899442504617 train_acc 1.0 valid_acc 0.9666\n","epoch 120 cost 237.84083190710885 train_acc 1.0 valid_acc 0.9661\n","epoch 121 cost 234.09569316536584 train_acc 1.0 valid_acc 0.966\n","epoch 122 cost 230.32178877243936 train_acc 1.0 valid_acc 0.9667\n","epoch 123 cost 227.65946545812216 train_acc 1.0 valid_acc 0.9662\n","epoch 124 cost 224.01425300812429 train_acc 1.0 valid_acc 0.9666\n","epoch 125 cost 220.13540490011695 train_acc 0.9999833333333333 valid_acc 0.9665\n","epoch 126 cost 217.61427059487798 train_acc 0.9999833333333333 valid_acc 0.9663\n","epoch 127 cost 214.62226023352127 train_acc 1.0 valid_acc 0.9665\n","epoch 128 cost 211.81282997605814 train_acc 1.0 valid_acc 0.9666\n","epoch 129 cost 207.41657142249838 train_acc 1.0 valid_acc 0.9669\n","epoch 130 cost 204.79311859027138 train_acc 1.0 valid_acc 0.9666\n","epoch 131 cost 201.94679625447492 train_acc 1.0 valid_acc 0.9664\n","epoch 132 cost 200.21805957026038 train_acc 1.0 valid_acc 0.9668\n","epoch 133 cost 196.7197831851313 train_acc 1.0 valid_acc 0.9668\n","epoch 134 cost 194.21473916433823 train_acc 0.9999833333333333 valid_acc 0.9663\n","epoch 135 cost 191.1544620367841 train_acc 0.9999833333333333 valid_acc 0.9666\n","epoch 136 cost 188.97196445111263 train_acc 0.9999833333333333 valid_acc 0.9667\n","epoch 137 cost 186.56999119667225 train_acc 1.0 valid_acc 0.9667\n","epoch 138 cost 183.6283927179719 train_acc 1.0 valid_acc 0.9666\n","epoch 139 cost 181.63919156600988 train_acc 1.0 valid_acc 0.9666\n","epoch 140 cost 179.58936568882774 train_acc 1.0 valid_acc 0.9666\n","epoch 141 cost 177.41959759688936 train_acc 1.0 valid_acc 0.9663\n","epoch 142 cost 174.60812328643215 train_acc 1.0 valid_acc 0.9668\n","epoch 143 cost 172.4641679876733 train_acc 1.0 valid_acc 0.9665\n","epoch 144 cost 170.44863159379437 train_acc 1.0 valid_acc 0.9667\n","epoch 145 cost 168.10039543113612 train_acc 1.0 valid_acc 0.9668\n","epoch 146 cost 165.89301792150457 train_acc 1.0 valid_acc 0.9665\n","epoch 147 cost 164.06788283902057 train_acc 1.0 valid_acc 0.9663\n","epoch 148 cost 162.78129860549697 train_acc 1.0 valid_acc 0.9664\n","epoch 149 cost 160.51553601639094 train_acc 1.0 valid_acc 0.9666\n"]},{"output_type":"execute_result","data":{"text/plain":["<__main__.MLP2 at 0x7f5aa2005f10>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["plt.plot(range(150), model.eval_['cost'],'b.-')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"dzzhIo5soaiI","executionInfo":{"status":"ok","timestamp":1652925086039,"user_tz":240,"elapsed":441,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"d00f1635-2093-4902-c23e-d30bb840e4e9"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f5a9f11cbd0>]"]},"metadata":{},"execution_count":13},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["plt.plot(range(150), model.eval_['train_acc'],'b.-')\n","plt.plot(range(150), model.eval_['valid_acc'],'rx-')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"_aJygTiPrrot","executionInfo":{"status":"ok","timestamp":1652925118191,"user_tz":240,"elapsed":219,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"0ae67bd4-ffee-457b-9d92-865a0c9979ab"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f5a9f011490>]"]},"metadata":{},"execution_count":15},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["y_pred = model.predict(X_test)"],"metadata":{"id":"guU4wc3vr2jf","executionInfo":{"status":"ok","timestamp":1652925164266,"user_tz":240,"elapsed":140,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","conf_mx = confusion_matrix(y_test, y_pred)\n","conf_mx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XYXe7xKsKYn","executionInfo":{"status":"ok","timestamp":1652925176796,"user_tz":240,"elapsed":143,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"8e23101b-4a65-4fa9-9d81-7803040770dc"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 963,    1,    2,    1,    1,    3,    4,    3,    2,    0],\n","       [   0, 1123,    5,    0,    0,    2,    3,    2,    0,    0],\n","       [   8,    3,  987,   10,    5,    2,    2,    7,    8,    0],\n","       [   0,    1,    4,  982,    0,    7,    0,    6,    7,    3],\n","       [   1,    0,    5,    0,  951,    0,    7,    3,    2,   13],\n","       [   6,    2,    1,   13,    2,  845,    6,    0,   14,    3],\n","       [   6,    3,    0,    0,    4,    6,  936,    0,    3,    0],\n","       [   0,    4,   16,    5,    1,    1,    0,  989,    3,    9],\n","       [   4,    1,    4,    5,    4,    8,    1,    6,  930,   11],\n","       [   1,    3,    2,    9,   10,    5,    0,   11,    8,  960]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["true_count = np.trace(conf_mx)\n","print('accuracy = %d/%d = %lf' % (true_count, len(y_test), true_count/len(y_test)) )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIFAMv3DsLyY","executionInfo":{"status":"ok","timestamp":1652925211932,"user_tz":240,"elapsed":152,"user":{"displayName":"Kai Zhang","userId":"07064777406155612696"}},"outputId":"3de5f4d3-4c57-4bb3-8866-0bceee2a8ddf"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy = 9666/10000 = 0.966600\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"M-N1CB8ysdf_"},"execution_count":null,"outputs":[]}]}